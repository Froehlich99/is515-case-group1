{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eae70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pm4py\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32203689",
   "metadata": {},
   "outputs": [],
   "source": [
    "xes_path = \"data/BPI_Challenge_2019-3-w-after.xes\"\n",
    "out_dir = \"outputs\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "SHAP_MAX_SAMPLES = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e92bddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "\n",
    "_invalid_re = re.compile(r\"[\\[\\]<>]\")\n",
    "_space_re = re.compile(r\"\\s+\")\n",
    "\n",
    "def sanitize_feature_names(cols):\n",
    "    out = []\n",
    "    seen = {}\n",
    "    for c in map(str, cols):\n",
    "        name = _invalid_re.sub(\"_\", c)\n",
    "        name = _space_re.sub(\"_\", name)\n",
    "        base = name\n",
    "        k = seen.get(base, 0)\n",
    "        if k > 0:\n",
    "            name = f\"{base}__dup{k}\"\n",
    "        seen[base] = k + 1\n",
    "        out.append(name)\n",
    "    return out\n",
    "\n",
    "def sanitize_columns(df):\n",
    "    df = df.copy()\n",
    "    df.columns = sanitize_feature_names(df.columns)\n",
    "    return df\n",
    "\n",
    "def canonicalize(name: str) -> str:\n",
    "    s = name.lower()\n",
    "    s = s.replace(\"case:\", \"\")\n",
    "    s = s.replace(\"(case)\", \"\")\n",
    "    s = s.strip()\n",
    "    s = re.sub(r\"[^a-z0-9]+\", \"\", s)\n",
    "    return s\n",
    "\n",
    "def resolve_case_columns(df, requested_labels):\n",
    "    canon_to_display = {canon: display for display, canon in requested_labels.items()}\n",
    "    found = {}\n",
    "    for col in df.columns:\n",
    "        c = canonicalize(col)\n",
    "        if c in canon_to_display and c not in found:\n",
    "            found[c] = col\n",
    "    resolved = {}\n",
    "    for canon, col in found.items():\n",
    "        display = canon_to_display[canon]\n",
    "        resolved[display] = col\n",
    "    return resolved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd680940",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pm4py.read_xes(xes_path)\n",
    "df = obj if isinstance(obj, pd.DataFrame) else pm4py.convert_to_dataframe(obj)\n",
    "\n",
    "CASE_ID = \"case:concept:name\"\n",
    "TS = \"time:timestamp\"\n",
    "\n",
    "# Timestamps\n",
    "df[TS] = pd.to_datetime(df[TS], errors=\"coerce\", utc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288579cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "case_bounds = df.groupby(CASE_ID)[TS].agg(case_start=\"min\", case_end=\"max\")\n",
    "case_bounds[\"case_duration\"] = case_bounds[\"case_end\"] - case_bounds[\"case_start\"]\n",
    "case_bounds[\"duration_days\"] = case_bounds[\"case_duration\"].dt.total_seconds() / (3600 * 24)\n",
    "case_bounds[\"duration_days\"] = case_bounds[\"duration_days\"].clip(upper=400)  # Changed to 400\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(case_bounds[\"duration_days\"], bins=100, kde=True)\n",
    "plt.title(\"Distribution of Case Duration (in days)\")\n",
    "plt.xlabel(\"Duration (days)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(out_dir, \"duration_distribution.png\"))\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156b6c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "requested = {\n",
    "    \"Item\": \"item\",\n",
    "    \"Item Type\": \"itemtype\",\n",
    "    \"Vendor\": \"vendor\",\n",
    "    \"Spend area text\": \"spendareatext\",\n",
    "    \"Sub spend area text\": \"subspendareatext\",\n",
    "}\n",
    "\n",
    "resolved = resolve_case_columns(df, requested)\n",
    "missing = [disp for disp in requested if disp not in resolved]\n",
    "if missing:\n",
    "    sample = [c for c in df.columns if (\"case\" in c.lower()) or (\"(case\" in c.lower())]\n",
    "    raise ValueError(\n",
    "        f\"Requested attributes not found: {missing}. \"\n",
    "        f\"Found candidate case columns (sample): {sample[:20]}\"\n",
    "    )\n",
    "\n",
    "selected_cols = [resolved[k] for k in requested.keys()]\n",
    "\n",
    "# Aggregate case-level values\n",
    "case_static = (\n",
    "    df.sort_values(TS)\n",
    "      .groupby(CASE_ID)[selected_cols]\n",
    "      .first()\n",
    ")\n",
    "\n",
    "# Add temporal features from case start timestamp\n",
    "case_static = case_static.join(case_bounds[\"case_start\"])\n",
    "case_static[\"start_year\"] = case_static[\"case_start\"].dt.year\n",
    "case_static[\"start_month\"] = case_static[\"case_start\"].dt.month\n",
    "case_static[\"start_day_of_week\"] = case_static[\"case_start\"].dt.dayofweek\n",
    "case_static[\"start_hour\"] = case_static[\"case_start\"].dt.hour\n",
    "case_static = case_static.drop(columns=[\"case_start\"])\n",
    "\n",
    "# Join target\n",
    "data = case_static.join(case_bounds[[\"duration_days\"]], how=\"inner\")\n",
    "data.index = data.index.rename(\"case_id\")\n",
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c779ed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [c for c in data.columns if c not in [\"case_id\", \"duration_days\"]]\n",
    "\n",
    "def is_bool_col(s):\n",
    "    return pd.api.types.is_bool_dtype(s) or str(s.dtype) in (\"bool\", \"boolean\")\n",
    "\n",
    "cat_cols = [c for c in feature_cols if (data[c].dtype == \"object\") or is_bool_col(data[c])]\n",
    "num_cols = [c for c in feature_cols if c not in cat_cols]\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", Pipeline(steps=[\n",
    "            (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "        ]), cat_cols),\n",
    "        (\"num\", Pipeline(steps=[\n",
    "            (\"imp\", SimpleImputer(strategy=\"median\"))\n",
    "        ]), num_cols),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "X_train, X_test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "y_train = X_train[\"duration_days\"].astype(float)\n",
    "y_test = X_test[\"duration_days\"].astype(float)\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train[feature_cols], y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "pre = pre.set_output(transform=\"pandas\")\n",
    "pre.fit(X_tr)\n",
    "\n",
    "X_tr_enc = sanitize_columns(pre.transform(X_tr))\n",
    "X_val_enc = sanitize_columns(pre.transform(X_val))\n",
    "X_test_enc = sanitize_columns(pre.transform(X_test[feature_cols]))\n",
    "\n",
    "if X_tr_enc.shape[1] == 0:\n",
    "    raise ValueError(\"Preprocessing produced 0 feature columns; check attribute selection and imputers.\")\n",
    "\n",
    "def sanitized_base(colname):\n",
    "    return sanitize_feature_names([colname])[0]\n",
    "\n",
    "base_map = {}\n",
    "for display, orig in resolved.items():\n",
    "    base_map[sanitized_base(orig)] = display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2fc117",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    n_estimators=3000,           \n",
    "    learning_rate=0.05,          \n",
    "    max_depth=6,                 \n",
    "    min_child_weight=3,          \n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    gamma=0.1,                   \n",
    "    reg_alpha=0.1,               \n",
    "    reg_lambda=1.0,              \n",
    "    random_state=42,\n",
    "    n_jobs=8,\n",
    "    early_stopping_rounds=50,\n",
    ")\n",
    "\n",
    "reg.fit(\n",
    "    X_tr_enc, y_tr,\n",
    "    eval_set=[(X_val_enc, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "preds = reg.predict(X_test_enc)\n",
    "mae = mean_absolute_error(y_test, preds)\n",
    "print(f\"MAE (days): {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13264bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(X_test_enc) > SHAP_MAX_SAMPLES:\n",
    "    X_shap = X_test_enc.sample(SHAP_MAX_SAMPLES, random_state=42)\n",
    "else:\n",
    "    X_shap = X_test_enc\n",
    "\n",
    "print(f\"Computing SHAP on {len(X_shap)} rows using XGBoost pred_contribs ...\")\n",
    "\n",
    "dtest = xgb.DMatrix(X_shap, feature_names=X_shap.columns.astype(str).tolist())\n",
    "contribs = reg.get_booster().predict(dtest, pred_contribs=True)\n",
    "shap_values = contribs[:, :-1]\n",
    "expected_value = contribs[:, -1].mean()\n",
    "\n",
    "ex = shap.Explanation(\n",
    "    values=shap_values,\n",
    "    base_values=np.full(X_shap.shape[0], expected_value),\n",
    "    data=X_shap.values,\n",
    "    feature_names=X_shap.columns.astype(str).tolist(),\n",
    ")\n",
    "\n",
    "shap.plots.violin(ex, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(out_dir, \"shap_summary_violin.png\"), dpi=150)\n",
    "plt.close()\n",
    "\n",
    "shap.plots.bar(ex, show=False)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(out_dir, \"shap_summary_bar.png\"), dpi=150)\n",
    "plt.close()\n",
    "\n",
    "col_names_str = X_shap.columns.astype(str).tolist()\n",
    "mean_abs_by_col = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "group_scores = {}\n",
    "for base_sanitized, display in base_map.items():\n",
    "    cat_prefix = f\"cat__{base_sanitized}_\"\n",
    "    num_name = f\"num__{base_sanitized}\"\n",
    "    idxs = [i for i, name in enumerate(col_names_str) if name.startswith(cat_prefix) or name == num_name]\n",
    "    group_scores[display] = float(mean_abs_by_col[idxs].sum()) if len(idxs) > 0 else 0.0\n",
    "\n",
    "group_df = pd.DataFrame({\n",
    "    \"feature\": list(group_scores.keys()),\n",
    "    \"mean_abs_shap_group\": list(group_scores.values())\n",
    "}).sort_values(\"mean_abs_shap_group\", ascending=False)\n",
    "\n",
    "group_df.to_csv(os.path.join(out_dir, \"shap_feature_groups.csv\"), index=False)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.barh(group_df[\"feature\"], group_df[\"mean_abs_shap_group\"])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"Mean |SHAP| (aggregated)\")\n",
    "plt.title(\"Global impact by original attribute\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(out_dir, \"shap_feature_groups_bar.png\"), dpi=150)\n",
    "plt.close()\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(f\"- {os.path.join(out_dir, 'duration_distribution.png')}\")\n",
    "print(f\"- {os.path.join(out_dir, 'shap_summary_violin.png')}\")\n",
    "print(f\"- {os.path.join(out_dir, 'shap_summary_bar.png')}\")\n",
    "print(f\"- {os.path.join(out_dir, 'shap_feature_groups.csv')}\")\n",
    "print(f\"- {os.path.join(out_dir, 'shap_feature_groups_bar.png')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is515-case-group1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
